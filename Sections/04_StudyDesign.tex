


\vspace{-.2cm}
\section{Study Design}
\label{Section:Methodology}

As illustrated in Figure~\ref{fig:overall_arch}, our methodology consists of four principal stages:  \textit{(A) Knowledge Base Construction}, involving the collection of relevant license information and associated metadata;  \textit{(B) Knowledge Graph Injection}, where the gathered license data are represented as structured triples;  \textit{(C) Knowledge Graph-Constrained LLM Reasoning}, which leverages the knowledge graph to provide structured, reliable, and context-enriched information that complements the inherently probabilistic knowledge of LLMs; and  \textit{(D) Explainability}, aimed at bridging the gap between the LLM’s internal representations and external, up-to-date knowledge to ensure transparent and verifiable outputs.

%We present \textit{LARK}, a framework that integrates \textbf{Knowledge Graphs}, \textbf{LLMs}, and \textbf{RAG} to overcome the limitations of existing approaches and support regulatory compliance. Figure~\ref{fig:overall_arch} illustrates the high-level architecture.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=1\textwidth]{Images/sketch.jpg}
    \caption{Sketch of the proposed KG-RAG framework.} 
 %   Proposed KG + LLM + RAG Architecture for License Compatibility and Regulatory Compliance. The framework integrates three key components: (1) A Neo4j-based knowledge graph that models licenses, dependencies, and their relationships; (2) An LLM-driven parser that extracts terms from custom licenses; and (3) A RAG module that retrieves relevant regulatory documents to ground explanations in authoritative sources.}
    \label{fig:overall_arch}
\end{figure*}


\subsection{Knowledge Base Construction}
\label{sec:Knowledge_Base_Construction}

The effectiveness of the system depends on gathering and using comprehensive and reliable license data. For this purpose, a multi-stage framework was established to collect, process, and structure license information.

\subsubsection{License Data}

We sourced license texts from the Open Source Initiative database\footnote{https://opensource.org/licenses}. Standardized identifiers and compatibility matrices were obtained from SPDX specifications\footnote{https://spdx.org/licenses/}, and dependency data via the Libraries.io API\footnote{https://libraries.io/}. For Python packages, license information was retrieved from the Python Package Index (PyPI)\footnote{https://libraries.io/pypi}.

To address license compatibility, we employed the open-source license recommender findOSSLicense\footnote{https://findosslicense.cs.ucy.ac.cy/}
 \cite{KapitsakiC21}. Using this approach, we successfully collected over 750 distinct license types, including full text and metadata for each.

So, for each license, we extracted detailed metadata including the license name, SPDX identifier, version information, approval date, submitting organization, license steward, and official URL. Additionally, we captured the license category (e.g., permissive, copyleft, proprietary), the full license text for semantic analysis and term extraction, as well as compatibility relationships derived from established matrices.

\subsubsection{Dependency Data}

Our dependency collection pipeline leverages multiple package repositories to ensure comprehensive coverage. We integrated data from Libraries.io, which aggregates information from major package managers including npm, Maven, PyPI, RubyGems, NuGet, and others, thereby providing extensive coverage of open-source dependencies across multiple programming languages and ecosystems. For Python-specific analysis, we directly integrated with PyPI to capture both open-source and proprietary packages, ensuring inclusion of packages not available through Libraries.io. Using this pipeline, we successfully collected over 20,000 dependencies along with their associated license information, resulting in a comprehensive dataset for compatibility analysis.


\subsection{KG Data Injection}
\label{sec:KG_Injection}

\subsubsection{Knowledge Graph Schema Design}

Our knowledge graph follows a structured schema that captures the complex relationships between software licenses, dependencies, and legal terms. The schema consists of three primary node types and their interconnections:

\textbf{Node Types:}
\begin{itemize}
    \item \textbf{License Nodes:} Represent individual software licenses with properties including \texttt{spdx\_id}, \texttt{name}, \texttt{version}, \texttt{category} (permissive/copyleft/proprietary), \texttt{approval\_date}, \texttt{steward}, \texttt{full\_text}, and \texttt{compatibility\_matrix\_source}.
    \item \textbf{Dependency Nodes:} Represent software packages with properties including \texttt{name}, \texttt{version}, \texttt{repository\_url}, \texttt{package\_manager}, \texttt{download\_count}, and \texttt{last\_updated}.
    \item \textbf{Term Nodes:} Represent legal concepts with properties including \texttt{term\_type} (obligation/permission/prohibition), \texttt{description}, \texttt{confidence\_score}, and \texttt{source\_clause}.
\end{itemize}

\textbf{Relationship Types:}
\begin{itemize}
    \item \texttt{HAS\_LICENSE}: Links dependencies to their governing licenses
    \item \texttt{IS\_COMPATIBLE\_WITH}: Indicates license compatibility relationships
    \item \texttt{IS\_INCOMPATIBLE\_WITH}: Indicates license incompatibility relationships
    \item \texttt{REQUIRES}: Links licenses to mandatory obligations
    \item \texttt{PROHIBITS}: Links licenses to restrictions
    \item \texttt{PERMITS}: Links licenses to granted permissions
    \item \texttt{HAS\_TERM}: Connects licenses to their constituent legal terms
\end{itemize}

\subsubsection{Graph Population Process}

Each of the 750 collected licenses was modeled as a node with detailed metadata, including SPDX identifiers, categorization, approval dates, steward organizations, and full license text. The 20,000 dependencies were also modeled as nodes, with metadata such as package names, versions, repository information, and usage statistics.

For widely used licenses, established compatibility matrices from OSI and SPDX were used to create direct compatibility relationships. For less common or custom licenses, we applied automated term parsing to extract obligations, permissions, and prohibitions, enabling compatibility inference via rule-based reasoning.

The resulting knowledge graph contains over 750 license nodes with full metadata, more than 20,000 dependency nodes from major repositories, extensive links connecting dependencies to their licenses, and comprehensive compatibility relationships from verified matrices and automated term analysis.


\subsection{KG Constrained LLM Reasoning}
\label{sec:KG_Constrained_Reasoning}

At this stage, the prompt is enriched using knowledge graph embeddings, which involves integrating the retrieved triples with the user’s original query to provide the model with additional structured context \cite{PanLWCWW24}.

The LARK framework unifies Knowledge Graph querying and LLM processing within a single pipeline, overcoming the limitations of standalone LLMs by grounding responses in structured knowledge.


\subsubsection{Query Processing and Dependency Extraction.}


The system begins with natural language query processing to extract dependency information from user queries, employing prompt engineering and few-shot learning techniques to handle diverse query formats. First, the LLM performs query classification to determine whether the query concerns a compatibility check, license inquiry, or explanation request, thus selecting the appropriate processing pipeline. Next, through dependency extraction, the model uses Named Entity Recognition and dependency parsing to identify package names, versions, and license information from queries such as “Can I use React with Apache 2.0?” or “What are the license conflicts in my project dependencies?”. Finally, query normalization is applied to standardize package names and handle variations (e.g., “react”, “React.js”, “facebook/react” → “react”) using fuzzy string matching and package registry lookups.


\subsubsection{Cypher Query Generation and Knowledge Graph Interaction.}

The extracted dependency information is converted into optimized Cypher queries that leverage the KG structure for efficient retrieval. The LLM dynamically constructs Cypher queries based on the extracted dependencies, incorporating fuzzy matching to handle package name variations and version mismatches. For packages not found through exact matches, the system applies similarity-based matching using cosine similarity on package names and descriptions, with a threshold of 0.85 for fuzzy matching. Additionally, license resolution is performed by querying multiple relationship types (e.g., has\_license, is\_compatible\_with, requires, and prohibits) to build comprehensive license profiles.
We provide a sample Cypher query in the \ref{APP2} to illustrate a worked-out demonstration of the system’s query translation process.


\subsubsection{Fuzzy Matching and Error Handling.}

To handle common inconsistencies and typos in package names, the system employs advanced matching strategies: it uses Levenshtein Distance to account for minor spelling differences (e.g., “express” vs. “expressjs”), semantic similarity via sentence transformers to identify packages with comparable descriptions or functionality, alias resolution by maintaining a mapping of frequent package aliases and alternative names, and version normalization to manage variations in semantic versioning (e.g., “1.0.0”, “1.0”, “1.x”).

\subsubsection{LLM-Based License Parsing and Compatibility Mapping.}

For licenses not covered by established compatibility matrices, we designed an automated LLM-based parsing framework that systematically extracts and analyzes key license provisions to infer potential compatibility relationships. The system employs natural language processing techniques to identify clauses related to usage rights, redistribution, modification, and commercialization, which are then mapped into a structured representation aligned with our knowledge graph schema. This enables reasoning over licenses that traditionally lack predefined compatibility information, including custom and proprietary agreements as well as many open-source licenses that are not incorporated into widely adopted compatibility references.

\subsubsection{LLM Output Structuring.}

The LLM produces structured JSON output that encapsulates the extracted license terms, each accompanied by confidence scores and references to the corresponding source text. To ensure reliability, the model is explicitly constrained to extract only factual terms present in the license, without engaging in interpretation or explainability.\\






%At this stage starts the augmentation process by using the KG embeddings to enrich the promptfor more accurate response generation. This consists at integrating the retrieved triplets with the original user’s query \cite{PanLWCWW24}.




\subsection{Explainability}
\label{sec:Explainability}

To enhance LLM performance, we integrate a Retrieval-Augmented Generation system to provide contextually relevant license data, drawing from a broad knowledge base that includes authoritative legal and compliance documents, not just license texts.

\subsubsection{Comprehensive Knowledge Base Construction}

We developed a multi-source knowledge base that combines license texts with authoritative legal and compliance literature. It includes the full text and metadata of over 750 collected licenses, legal literature \cite{Haddad2018OpenSource,meeker2020open,2022open}, academic articles from IEEE and ACM, regulatory guidelines and compliance frameworks from organizations such as the Software Freedom Law Center\footnote{https://softwarefreedom.org/}, Free Software Foundation\footnote{https://www.fsf.org/}, and Open Source Initiative, and case studies\footnote{https://web.law.duke.edu/}\footnote{law.justia.com} encompassing legal precedents and court decisions related to software licensing across various jurisdictions.


\subsubsection{Document Processing Pipeline}

All collected documents undergo a specialized processing pipeline optimized for legal text analysis. First, legal texts are cleaned and normalized while preserving original formatting and structure to ensure accurate citation tracking. Next, documents are split chunks, taking care to preserve legal clause boundaries. Each chunk retains comprehensive metadata, including source document, page numbers, section references, publication year, and document type (license, book, article, or case study). Embeddings are then generated for each chunk.
This process resulted in over 25,000 indexed chunks across all sources, enabling comprehensive semantic retrieval with precise citation capabilities.

\subsubsection{RAG-Enhanced Response Generation.}

Upon retrieving structured data from the knowledge graph, the LLM employs a RAG framework to produce comprehensive, evidence-based explanations. Initially, relevant context is assembled by integrating KG information with legal documents retrieved from the vector database through semantic similarity. The system then incorporates precise citations by identifying pertinent legal clauses, court rulings, or regulatory references that substantiate the compatibility analysis. Subsequently, the adopted LLM synthesizes the structured data and retrieved legal context into coherent, human-readable explanations. Finally, all generated responses are rigorously validated against KG constraints to ensure accuracy and prevent potential hallucinations, thereby maintaining the reliability of the final output.

In \ref{APP1}, we provide a worked example of how our LARK license compatibility analysis pipeline works.

%Next, documents are split using RecursiveCharacterTextSplitter into chunks of 512 tokens with a 50-token overlap, taking care to preserve legal clause boundaries. Each chunk retains comprehensive metadata, including source document, page numbers, section references, publication year, and document type (license, book, article, or case study). OpenAI’s text-embedding-ada-002 model is then used to generate 1,536-dimensional embeddings for each chunk, which are stored in ChromaDB for efficient similarity search and persistent retrieval. This process resulted in over 25,000 indexed chunks across all sources, enabling comprehensive semantic retrieval with precise citation capabilities.



%, legal literature such as Open Source Compliance in the Enterprise by Ibrahim Haddad, Software License Compliance by Heather Meeker, and Open Source Software: Law, Policy, and Practice by Niva Elkin-Koren, academic articles from IEEE and ACM including License Compliance in Open Source Software Development (IEEE Software), Automated License Analysis: A Systematic Review (ACM Computing Surveys), and Legal Aspects of Open Source Software (IEEE Computer), regulatory guidelines and compliance frameworks from organizations such as the Software Freedom Law Center, Free Software Foundation, and Open Source Initiative, and case studies encompassing legal precedents and court decisions related to software licensing across various jurisdictions.


%As primary open-source license texts and metadata, we used the Open Source Initiative database\footnote{https://opensource.org/licenses}. We also relied on SPDX specifications\footnote{https://spdx.org/licenses/} to provide standardized license identifiers and compatibility matrices and Libraries.io API\footnote{https://libraries.io/} to get the dependency data related to major package repositories. As we are mainly focusing on Python-specific packages in this work, we proceed with Python Package Index (PyPI)\footnote{https://libraries.io/pypi} to get its related license information.



